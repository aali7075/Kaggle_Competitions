{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import linalg as LA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    def __init__(self, target_explained_variance=None):\n",
    "        \"\"\"\n",
    "        explained_variance: float, the target level of explained variance\n",
    "        \"\"\"\n",
    "        self.target_explained_variance = target_explained_variance\n",
    "        self.feature_size = -1\n",
    "        self.feature_tuple=[] #has the index of feature and amount of pca\n",
    "\n",
    "    def standardize(self, X):\n",
    "        \"\"\"\n",
    "        standardize features using standard scaler\n",
    "        :param m X n: features data\n",
    "        :return: standardized features\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X) #fit the data to find std and mean\n",
    "        return scaler.transform(X)\n",
    "\n",
    "    def compute_mean_vector(self, X_std):\n",
    "        \"\"\"\n",
    "        compute mean vector\n",
    "        :param X_std: data\n",
    "        :return n X 1 matrix: mean vector\n",
    "        \"\"\"\n",
    "        np_x=np.array(X_std)\n",
    "        means=np.mean(np_x,axis=0)\n",
    "        return means\n",
    "\n",
    "    def compute_cov(self, X_std, mean_vec):\n",
    "        \"\"\"\n",
    "        Covariance using mean, (don't use any numpy.cov)\n",
    "        :param X_std:\n",
    "        :param mean_vec:\n",
    "        :return n X n matrix:: covariance matrix\n",
    "        \"\"\"\n",
    "        len_x=len(X_std[0])\n",
    "        print(len_x)\n",
    "        scale=1/(len(X_std)-1)\n",
    "        print(\"scale is \", scale)\n",
    "        val=[]\n",
    "        for i in range(len_x):\n",
    "            row=X_std[:,i]-mean_vec[i] #compute ith row\n",
    "            for j in range(len_x):\n",
    "                col=X_std[:,j]-mean_vec[j]\n",
    "                val.append(np.sum(np.multiply(row,col)))\n",
    "        val=np.array(val)\n",
    "        val=val.reshape(len_x,len_x)\n",
    "        val=scale*val\n",
    "        return val\n",
    "\n",
    "    def compute_eigen_vector(self, cov_mat):\n",
    "        \"\"\"\n",
    "        Eigenvector and eigen values using numpy\n",
    "        :param cov_mat:\n",
    "        :return: (eigen_vector,eigen_values)\n",
    "        \"\"\"\n",
    "        v,w= LA.eig(cov_mat) #v is the eigen value and w is eigen vector\n",
    "        return w,v\n",
    "\n",
    "    def compute_explained_variance(self, eigen_vals):\n",
    "        \"\"\"\n",
    "        sort eigen values and compute explained variance.\n",
    "        explained variance informs the amount of information (variance)\n",
    "        can be attributed to each of  the principal components.\n",
    "        :param eigen_vals:\n",
    "        :return: explained variance.\n",
    "        \"\"\"\n",
    "        eigen_vals_copy=eigen_vals\n",
    "        eigen_vals_sorted=np.sort(eigen_vals)[::-1]\n",
    "        print(\"largest eigen_vals is \", eigen_vals_sorted[0])\n",
    "        eigen_sum=np.sum(eigen_vals)\n",
    "        var_exp=eigen_vals/eigen_sum\n",
    "        for val in eigen_vals_sorted:\n",
    "            for i in range(len(eigen_vals_copy)):\n",
    "                if val == eigen_vals_copy[i]:\n",
    "                    self.feature_tuple.append((i,val/eigen_sum))\n",
    "                    \n",
    "        return var_exp\n",
    "\n",
    "    def cumulative_sum(self, var_exp):\n",
    "        \"\"\"\n",
    "        return cumulative sum of explained variance.\n",
    "        :param var_exp: explained variance\n",
    "        :return: cumulative explained variance\n",
    "        \"\"\"\n",
    "        return np.cumsum(var_exp)\n",
    "\n",
    "    def compute_weight_matrix(self, eig_pairs, cum_var_exp):\n",
    "        \"\"\"\n",
    "        compute weight matrix of top principal components conditioned on target\n",
    "        explained variance.\n",
    "        (Hint : use cumilative explained variance and target_explained_variance to find\n",
    "        top components)\n",
    "        \n",
    "        :param eig_pairs: list of tuples containing eigenvector and eigen\n",
    "        values\n",
    "        :param cum_var_exp: cumulative expalined variance by features\n",
    "        :return: weight matrix\n",
    "        \"\"\"\n",
    "        for i in range(len(cum_var_exp)):\n",
    "            if(cum_var_exp[i]>=self.target_explained_variance): #find the amount of features\n",
    "                index=i\n",
    "                break;\n",
    "        print(\"i is \", index)\n",
    "        w,v=zip(*eig_pairs) #unzip the values, note eig_pairs sorted in descending order\n",
    "        w=np.array(w)\n",
    "        weight_matrix=w[:,0:index]\n",
    "        return weight_matrix\n",
    "\n",
    "    def transform_data(self, X_std, matrix_w):\n",
    "        \"\"\"\n",
    "        transform data to subspace using weight matrix\n",
    "        :param X_std: standardized data\n",
    "        :param matrix_w: weight matrix\n",
    "        :return: data in the subspace\n",
    "        \"\"\"\n",
    "        return X_std.dot(matrix_w)\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        entry point to the transform data to k dimensions\n",
    "        standardize and compute weight matrix to transform data.\n",
    "        :param   m X n dimension: train samples\n",
    "        :return  m X k dimension: subspace data.\n",
    "        \"\"\"\n",
    "    \n",
    "        X_std=self.standardize(X)\n",
    "        mean_vec=self.compute_mean_vector(X_std)\n",
    "        co_var=self.compute_cov(X_std,mean_vec)\n",
    "        w,v=self.compute_eigen_vector(co_var)\n",
    "        var_exp=self.compute_explained_variance(v)\n",
    "        cum_var_sum=self.cumulative_sum(var_exp)\n",
    "        eigen_pairs=tuple(zip(w, v))\n",
    "        sorted(eigen_pairs, key=lambda x: x[1])\n",
    "        matrix_w=self.compute_weight_matrix(eigen_pairs,cum_var_sum)\n",
    "        \n",
    "        \n",
    "        return self.transform_data(X_std=X_std, matrix_w=matrix_w), self.feature_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>PPE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>numPulses</th>\n",
       "      <th>numPeriodsPulses</th>\n",
       "      <th>meanPeriodPulses</th>\n",
       "      <th>stdDevPeriodPulses</th>\n",
       "      <th>locPctJitter</th>\n",
       "      <th>locAbsJitter</th>\n",
       "      <th>...</th>\n",
       "      <th>tqwt_kurtosisValue_dec_28</th>\n",
       "      <th>tqwt_kurtosisValue_dec_29</th>\n",
       "      <th>tqwt_kurtosisValue_dec_30</th>\n",
       "      <th>tqwt_kurtosisValue_dec_31</th>\n",
       "      <th>tqwt_kurtosisValue_dec_32</th>\n",
       "      <th>tqwt_kurtosisValue_dec_33</th>\n",
       "      <th>tqwt_kurtosisValue_dec_34</th>\n",
       "      <th>tqwt_kurtosisValue_dec_35</th>\n",
       "      <th>tqwt_kurtosisValue_dec_36</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85247</td>\n",
       "      <td>0.71826</td>\n",
       "      <td>0.57227</td>\n",
       "      <td>240</td>\n",
       "      <td>239</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.00218</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5620</td>\n",
       "      <td>2.6445</td>\n",
       "      <td>3.8686</td>\n",
       "      <td>4.2105</td>\n",
       "      <td>5.1221</td>\n",
       "      <td>4.4625</td>\n",
       "      <td>2.6202</td>\n",
       "      <td>3.0004</td>\n",
       "      <td>18.9405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76686</td>\n",
       "      <td>0.69481</td>\n",
       "      <td>0.53966</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.00195</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5589</td>\n",
       "      <td>3.6107</td>\n",
       "      <td>23.5155</td>\n",
       "      <td>14.1962</td>\n",
       "      <td>11.0261</td>\n",
       "      <td>9.5082</td>\n",
       "      <td>6.5245</td>\n",
       "      <td>6.3431</td>\n",
       "      <td>45.1780</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85083</td>\n",
       "      <td>0.67604</td>\n",
       "      <td>0.58982</td>\n",
       "      <td>232</td>\n",
       "      <td>231</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.00176</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5643</td>\n",
       "      <td>2.3308</td>\n",
       "      <td>9.4959</td>\n",
       "      <td>10.7458</td>\n",
       "      <td>11.0177</td>\n",
       "      <td>4.8066</td>\n",
       "      <td>2.9199</td>\n",
       "      <td>3.1495</td>\n",
       "      <td>4.7666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41121</td>\n",
       "      <td>0.79672</td>\n",
       "      <td>0.59257</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7805</td>\n",
       "      <td>3.5664</td>\n",
       "      <td>5.2558</td>\n",
       "      <td>14.0403</td>\n",
       "      <td>4.2235</td>\n",
       "      <td>4.6857</td>\n",
       "      <td>4.8460</td>\n",
       "      <td>6.2650</td>\n",
       "      <td>4.0603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.32790</td>\n",
       "      <td>0.79782</td>\n",
       "      <td>0.53028</td>\n",
       "      <td>236</td>\n",
       "      <td>235</td>\n",
       "      <td>0.008162</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.00535</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1727</td>\n",
       "      <td>5.8416</td>\n",
       "      <td>6.0805</td>\n",
       "      <td>5.7621</td>\n",
       "      <td>7.7817</td>\n",
       "      <td>11.6891</td>\n",
       "      <td>8.2103</td>\n",
       "      <td>5.0559</td>\n",
       "      <td>6.1164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.80903</td>\n",
       "      <td>0.56355</td>\n",
       "      <td>0.28385</td>\n",
       "      <td>417</td>\n",
       "      <td>416</td>\n",
       "      <td>0.004627</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.00064</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0706</td>\n",
       "      <td>3.0190</td>\n",
       "      <td>3.1212</td>\n",
       "      <td>2.4921</td>\n",
       "      <td>3.5844</td>\n",
       "      <td>3.5400</td>\n",
       "      <td>3.3805</td>\n",
       "      <td>3.2003</td>\n",
       "      <td>6.8671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>0.16084</td>\n",
       "      <td>0.56499</td>\n",
       "      <td>0.59194</td>\n",
       "      <td>415</td>\n",
       "      <td>413</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.00143</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9704</td>\n",
       "      <td>1.7451</td>\n",
       "      <td>1.8277</td>\n",
       "      <td>2.4976</td>\n",
       "      <td>5.2981</td>\n",
       "      <td>4.2616</td>\n",
       "      <td>6.3042</td>\n",
       "      <td>10.9058</td>\n",
       "      <td>28.4170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>753</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88389</td>\n",
       "      <td>0.72335</td>\n",
       "      <td>0.46815</td>\n",
       "      <td>381</td>\n",
       "      <td>380</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>51.5607</td>\n",
       "      <td>44.4641</td>\n",
       "      <td>26.1586</td>\n",
       "      <td>6.3076</td>\n",
       "      <td>2.8601</td>\n",
       "      <td>2.5361</td>\n",
       "      <td>3.5377</td>\n",
       "      <td>3.3545</td>\n",
       "      <td>5.0424</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>754</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83782</td>\n",
       "      <td>0.74890</td>\n",
       "      <td>0.49823</td>\n",
       "      <td>340</td>\n",
       "      <td>339</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.00092</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>19.1607</td>\n",
       "      <td>12.8312</td>\n",
       "      <td>8.9434</td>\n",
       "      <td>2.2044</td>\n",
       "      <td>1.9496</td>\n",
       "      <td>1.9664</td>\n",
       "      <td>2.6801</td>\n",
       "      <td>2.8332</td>\n",
       "      <td>3.7131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>755</td>\n",
       "      <td>0</td>\n",
       "      <td>0.81304</td>\n",
       "      <td>0.76471</td>\n",
       "      <td>0.46374</td>\n",
       "      <td>340</td>\n",
       "      <td>339</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.00078</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>62.9927</td>\n",
       "      <td>21.8152</td>\n",
       "      <td>9.2457</td>\n",
       "      <td>4.8555</td>\n",
       "      <td>3.0551</td>\n",
       "      <td>3.0415</td>\n",
       "      <td>4.0116</td>\n",
       "      <td>2.6217</td>\n",
       "      <td>3.1527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>756 rows × 754 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender      PPE      DFA     RPDE  numPulses  numPeriodsPulses  \\\n",
       "0         1  0.85247  0.71826  0.57227        240               239   \n",
       "1         1  0.76686  0.69481  0.53966        234               233   \n",
       "2         1  0.85083  0.67604  0.58982        232               231   \n",
       "3         0  0.41121  0.79672  0.59257        178               177   \n",
       "4         0  0.32790  0.79782  0.53028        236               235   \n",
       "..      ...      ...      ...      ...        ...               ...   \n",
       "751       0  0.80903  0.56355  0.28385        417               416   \n",
       "752       0  0.16084  0.56499  0.59194        415               413   \n",
       "753       0  0.88389  0.72335  0.46815        381               380   \n",
       "754       0  0.83782  0.74890  0.49823        340               339   \n",
       "755       0  0.81304  0.76471  0.46374        340               339   \n",
       "\n",
       "     meanPeriodPulses  stdDevPeriodPulses  locPctJitter  locAbsJitter  ...  \\\n",
       "0            0.008064            0.000087       0.00218      0.000018  ...   \n",
       "1            0.008258            0.000073       0.00195      0.000016  ...   \n",
       "2            0.008340            0.000060       0.00176      0.000015  ...   \n",
       "3            0.010858            0.000183       0.00419      0.000046  ...   \n",
       "4            0.008162            0.002669       0.00535      0.000044  ...   \n",
       "..                ...                 ...           ...           ...  ...   \n",
       "751          0.004627            0.000052       0.00064      0.000003  ...   \n",
       "752          0.004550            0.000220       0.00143      0.000006  ...   \n",
       "753          0.005069            0.000103       0.00076      0.000004  ...   \n",
       "754          0.005679            0.000055       0.00092      0.000005  ...   \n",
       "755          0.005676            0.000037       0.00078      0.000004  ...   \n",
       "\n",
       "     tqwt_kurtosisValue_dec_28  tqwt_kurtosisValue_dec_29  \\\n",
       "0                       1.5620                     2.6445   \n",
       "1                       1.5589                     3.6107   \n",
       "2                       1.5643                     2.3308   \n",
       "3                       3.7805                     3.5664   \n",
       "4                       6.1727                     5.8416   \n",
       "..                         ...                        ...   \n",
       "751                     3.0706                     3.0190   \n",
       "752                     1.9704                     1.7451   \n",
       "753                    51.5607                    44.4641   \n",
       "754                    19.1607                    12.8312   \n",
       "755                    62.9927                    21.8152   \n",
       "\n",
       "     tqwt_kurtosisValue_dec_30  tqwt_kurtosisValue_dec_31  \\\n",
       "0                       3.8686                     4.2105   \n",
       "1                      23.5155                    14.1962   \n",
       "2                       9.4959                    10.7458   \n",
       "3                       5.2558                    14.0403   \n",
       "4                       6.0805                     5.7621   \n",
       "..                         ...                        ...   \n",
       "751                     3.1212                     2.4921   \n",
       "752                     1.8277                     2.4976   \n",
       "753                    26.1586                     6.3076   \n",
       "754                     8.9434                     2.2044   \n",
       "755                     9.2457                     4.8555   \n",
       "\n",
       "     tqwt_kurtosisValue_dec_32  tqwt_kurtosisValue_dec_33  \\\n",
       "0                       5.1221                     4.4625   \n",
       "1                      11.0261                     9.5082   \n",
       "2                      11.0177                     4.8066   \n",
       "3                       4.2235                     4.6857   \n",
       "4                       7.7817                    11.6891   \n",
       "..                         ...                        ...   \n",
       "751                     3.5844                     3.5400   \n",
       "752                     5.2981                     4.2616   \n",
       "753                     2.8601                     2.5361   \n",
       "754                     1.9496                     1.9664   \n",
       "755                     3.0551                     3.0415   \n",
       "\n",
       "     tqwt_kurtosisValue_dec_34  tqwt_kurtosisValue_dec_35  \\\n",
       "0                       2.6202                     3.0004   \n",
       "1                       6.5245                     6.3431   \n",
       "2                       2.9199                     3.1495   \n",
       "3                       4.8460                     6.2650   \n",
       "4                       8.2103                     5.0559   \n",
       "..                         ...                        ...   \n",
       "751                     3.3805                     3.2003   \n",
       "752                     6.3042                    10.9058   \n",
       "753                     3.5377                     3.3545   \n",
       "754                     2.6801                     2.8332   \n",
       "755                     4.0116                     2.6217   \n",
       "\n",
       "     tqwt_kurtosisValue_dec_36  class  \n",
       "0                      18.9405      1  \n",
       "1                      45.1780      1  \n",
       "2                       4.7666      1  \n",
       "3                       4.0603      1  \n",
       "4                       6.1164      1  \n",
       "..                         ...    ...  \n",
       "751                     6.8671      0  \n",
       "752                    28.4170      0  \n",
       "753                     5.0424      0  \n",
       "754                     3.7131      0  \n",
       "755                     3.1527      0  \n",
       "\n",
       "[756 rows x 754 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=pd.read_csv(\"pd_speech_features.csv\", header=1)\n",
    "file= file.drop([\"id\"], axis=1) #Don't want to predict on id\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aali7075/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[440, 368, 331, 584, 477, 346, 370, 347, 580, 513]\n",
      "accuracy score:  0.8412698412698413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.65        42\n",
      "           1       0.90      0.89      0.90       147\n",
      "\n",
      "    accuracy                           0.84       189\n",
      "   macro avg       0.77      0.78      0.77       189\n",
      "weighted avg       0.84      0.84      0.84       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_vals= file[\"class\"]\n",
    "x_vals= file.drop([\"class\"], axis=1)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_vals) #fit the data to find std and mean\n",
    "x_vals=scaler.transform(x_vals)\n",
    "x, x_test, y, y_test = train_test_split(x_vals, y_vals, test_size = .25)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(x, y)\n",
    "y_pred=clf.predict(x_test)\n",
    "x=clf.feature_importances_\n",
    "#print(x)\n",
    "x_sorted=np.sort(x)[::-1]\n",
    "x_sorted\n",
    "\n",
    "important_feats=[]\n",
    "\n",
    "for val in x_sorted:\n",
    "    for i in range(len(x)):\n",
    "        if val==x[i]:\n",
    "            important_feats.append(i)\n",
    "print(important_feats[:10])\n",
    "\n",
    "\n",
    "print('accuracy score: ',accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are currently 754 attributes. With many of thoses being insignificant, we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753\n",
      "scale is  0.0013245033112582781\n",
      "largest eigen_vals is  97.7331202728519\n",
      "i is  270\n"
     ]
    }
   ],
   "source": [
    "y_vals= file[\"class\"]\n",
    "x_vals= file.drop([\"class\"], axis=1)\n",
    "x_array=x_vals.values\n",
    "pca_instance=PCA(.99)\n",
    "t,feature_tuple=pca_instance.fit(x_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get a 99% of the data we only need 270 of the attributes ###\n",
    "Seems as though the data has already done PCA on the data and ordered the column features from most to least important with only a slight variation from what we found to be most important.\n",
    "Now only keep the columns from the pca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>PPE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>numPulses</th>\n",
       "      <th>numPeriodsPulses</th>\n",
       "      <th>meanPeriodPulses</th>\n",
       "      <th>stdDevPeriodPulses</th>\n",
       "      <th>locPctJitter</th>\n",
       "      <th>locAbsJitter</th>\n",
       "      <th>...</th>\n",
       "      <th>det_LT_TKEO_mean_1_coef</th>\n",
       "      <th>det_LT_entropy_log_8_coef</th>\n",
       "      <th>det_LT_entropy_log_9_coef</th>\n",
       "      <th>det_LT_entropy_log_10_coef</th>\n",
       "      <th>det_LT_TKEO_mean_5_coef</th>\n",
       "      <th>det_LT_TKEO_mean_8_coef</th>\n",
       "      <th>det_LT_TKEO_mean_4_coef</th>\n",
       "      <th>det_LT_TKEO_mean_9_coef</th>\n",
       "      <th>det_LT_entropy_log_7_coef</th>\n",
       "      <th>det_LT_entropy_log_5_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85247</td>\n",
       "      <td>0.71826</td>\n",
       "      <td>0.57227</td>\n",
       "      <td>240</td>\n",
       "      <td>239</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.00218</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>...</td>\n",
       "      <td>1.620000e-07</td>\n",
       "      <td>-192.1166</td>\n",
       "      <td>-175.6679</td>\n",
       "      <td>-163.4186</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>-190.3697</td>\n",
       "      <td>-182.3583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76686</td>\n",
       "      <td>0.69481</td>\n",
       "      <td>0.53966</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.00195</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>...</td>\n",
       "      <td>2.490000e-07</td>\n",
       "      <td>-173.3484</td>\n",
       "      <td>-177.7185</td>\n",
       "      <td>-166.2056</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>-209.3696</td>\n",
       "      <td>-197.9376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85083</td>\n",
       "      <td>0.67604</td>\n",
       "      <td>0.58982</td>\n",
       "      <td>232</td>\n",
       "      <td>231</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.00176</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>1.270000e-07</td>\n",
       "      <td>-193.0940</td>\n",
       "      <td>-203.4729</td>\n",
       "      <td>-183.1261</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-204.3601</td>\n",
       "      <td>-211.9958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41121</td>\n",
       "      <td>0.79672</td>\n",
       "      <td>0.59257</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>...</td>\n",
       "      <td>7.283200e-03</td>\n",
       "      <td>-45.5159</td>\n",
       "      <td>-53.0037</td>\n",
       "      <td>-37.7727</td>\n",
       "      <td>0.183850</td>\n",
       "      <td>2.315000</td>\n",
       "      <td>0.164130</td>\n",
       "      <td>0.418610</td>\n",
       "      <td>-56.7015</td>\n",
       "      <td>-70.0220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.32790</td>\n",
       "      <td>0.79782</td>\n",
       "      <td>0.53028</td>\n",
       "      <td>236</td>\n",
       "      <td>235</td>\n",
       "      <td>0.008162</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.00535</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>...</td>\n",
       "      <td>6.293400e-03</td>\n",
       "      <td>-45.4301</td>\n",
       "      <td>-34.3376</td>\n",
       "      <td>-8.3446</td>\n",
       "      <td>0.196080</td>\n",
       "      <td>0.557800</td>\n",
       "      <td>0.241060</td>\n",
       "      <td>0.777480</td>\n",
       "      <td>-54.6934</td>\n",
       "      <td>-66.5583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.80903</td>\n",
       "      <td>0.56355</td>\n",
       "      <td>0.28385</td>\n",
       "      <td>417</td>\n",
       "      <td>416</td>\n",
       "      <td>0.004627</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.00064</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>2.330000e-07</td>\n",
       "      <td>-158.8007</td>\n",
       "      <td>-161.6918</td>\n",
       "      <td>-134.1501</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>-166.0632</td>\n",
       "      <td>-212.9824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>0.16084</td>\n",
       "      <td>0.56499</td>\n",
       "      <td>0.59194</td>\n",
       "      <td>415</td>\n",
       "      <td>413</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.00143</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>8.850400e-03</td>\n",
       "      <td>-110.1041</td>\n",
       "      <td>-101.9914</td>\n",
       "      <td>-91.7575</td>\n",
       "      <td>0.181090</td>\n",
       "      <td>0.061777</td>\n",
       "      <td>0.161580</td>\n",
       "      <td>0.010785</td>\n",
       "      <td>-120.5312</td>\n",
       "      <td>-121.5467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>753</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88389</td>\n",
       "      <td>0.72335</td>\n",
       "      <td>0.46815</td>\n",
       "      <td>381</td>\n",
       "      <td>380</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>2.110000e-07</td>\n",
       "      <td>-128.4035</td>\n",
       "      <td>-117.1867</td>\n",
       "      <td>-85.7921</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.007064</td>\n",
       "      <td>-207.2320</td>\n",
       "      <td>-229.7496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>754</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83782</td>\n",
       "      <td>0.74890</td>\n",
       "      <td>0.49823</td>\n",
       "      <td>340</td>\n",
       "      <td>339</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.00092</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>1.810000e-07</td>\n",
       "      <td>-153.4097</td>\n",
       "      <td>-171.0194</td>\n",
       "      <td>-139.3763</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>-180.0185</td>\n",
       "      <td>-221.9074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>755</td>\n",
       "      <td>0</td>\n",
       "      <td>0.81304</td>\n",
       "      <td>0.76471</td>\n",
       "      <td>0.46374</td>\n",
       "      <td>340</td>\n",
       "      <td>339</td>\n",
       "      <td>0.005676</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.00078</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>1.230000e-07</td>\n",
       "      <td>-194.7723</td>\n",
       "      <td>-203.6263</td>\n",
       "      <td>-190.1832</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-192.1787</td>\n",
       "      <td>-211.4916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>756 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender      PPE      DFA     RPDE  numPulses  numPeriodsPulses  \\\n",
       "0         1  0.85247  0.71826  0.57227        240               239   \n",
       "1         1  0.76686  0.69481  0.53966        234               233   \n",
       "2         1  0.85083  0.67604  0.58982        232               231   \n",
       "3         0  0.41121  0.79672  0.59257        178               177   \n",
       "4         0  0.32790  0.79782  0.53028        236               235   \n",
       "..      ...      ...      ...      ...        ...               ...   \n",
       "751       0  0.80903  0.56355  0.28385        417               416   \n",
       "752       0  0.16084  0.56499  0.59194        415               413   \n",
       "753       0  0.88389  0.72335  0.46815        381               380   \n",
       "754       0  0.83782  0.74890  0.49823        340               339   \n",
       "755       0  0.81304  0.76471  0.46374        340               339   \n",
       "\n",
       "     meanPeriodPulses  stdDevPeriodPulses  locPctJitter  locAbsJitter  ...  \\\n",
       "0            0.008064            0.000087       0.00218      0.000018  ...   \n",
       "1            0.008258            0.000073       0.00195      0.000016  ...   \n",
       "2            0.008340            0.000060       0.00176      0.000015  ...   \n",
       "3            0.010858            0.000183       0.00419      0.000046  ...   \n",
       "4            0.008162            0.002669       0.00535      0.000044  ...   \n",
       "..                ...                 ...           ...           ...  ...   \n",
       "751          0.004627            0.000052       0.00064      0.000003  ...   \n",
       "752          0.004550            0.000220       0.00143      0.000006  ...   \n",
       "753          0.005069            0.000103       0.00076      0.000004  ...   \n",
       "754          0.005679            0.000055       0.00092      0.000005  ...   \n",
       "755          0.005676            0.000037       0.00078      0.000004  ...   \n",
       "\n",
       "     det_LT_TKEO_mean_1_coef  det_LT_entropy_log_8_coef  \\\n",
       "0               1.620000e-07                  -192.1166   \n",
       "1               2.490000e-07                  -173.3484   \n",
       "2               1.270000e-07                  -193.0940   \n",
       "3               7.283200e-03                   -45.5159   \n",
       "4               6.293400e-03                   -45.4301   \n",
       "..                       ...                        ...   \n",
       "751             2.330000e-07                  -158.8007   \n",
       "752             8.850400e-03                  -110.1041   \n",
       "753             2.110000e-07                  -128.4035   \n",
       "754             1.810000e-07                  -153.4097   \n",
       "755             1.230000e-07                  -194.7723   \n",
       "\n",
       "     det_LT_entropy_log_9_coef  det_LT_entropy_log_10_coef  \\\n",
       "0                    -175.6679                   -163.4186   \n",
       "1                    -177.7185                   -166.2056   \n",
       "2                    -203.4729                   -183.1261   \n",
       "3                     -53.0037                    -37.7727   \n",
       "4                     -34.3376                     -8.3446   \n",
       "..                         ...                         ...   \n",
       "751                  -161.6918                   -134.1501   \n",
       "752                  -101.9914                    -91.7575   \n",
       "753                  -117.1867                    -85.7921   \n",
       "754                  -171.0194                   -139.3763   \n",
       "755                  -203.6263                   -190.1832   \n",
       "\n",
       "     det_LT_TKEO_mean_5_coef  det_LT_TKEO_mean_8_coef  \\\n",
       "0                   0.000500                 0.000229   \n",
       "1                   0.000417                 0.001210   \n",
       "2                   0.000170                 0.000007   \n",
       "3                   0.183850                 2.315000   \n",
       "4                   0.196080                 0.557800   \n",
       "..                       ...                      ...   \n",
       "751                 0.000637                 0.002324   \n",
       "752                 0.181090                 0.061777   \n",
       "753                 0.000012                 0.002499   \n",
       "754                 0.000077                 0.004613   \n",
       "755                 0.000235                 0.000042   \n",
       "\n",
       "     det_LT_TKEO_mean_4_coef  det_LT_TKEO_mean_9_coef  \\\n",
       "0                   0.000104                 0.000132   \n",
       "1                   0.000253                 0.000094   \n",
       "2                   0.000228                 0.000012   \n",
       "3                   0.164130                 0.418610   \n",
       "4                   0.241060                 0.777480   \n",
       "..                       ...                      ...   \n",
       "751                 0.000052                 0.000995   \n",
       "752                 0.161580                 0.010785   \n",
       "753                 0.000077                 0.007064   \n",
       "754                 0.000242                 0.000350   \n",
       "755                 0.000043                 0.000017   \n",
       "\n",
       "     det_LT_entropy_log_7_coef  det_LT_entropy_log_5_coef  \n",
       "0                    -190.3697                  -182.3583  \n",
       "1                    -209.3696                  -197.9376  \n",
       "2                    -204.3601                  -211.9958  \n",
       "3                     -56.7015                   -70.0220  \n",
       "4                     -54.6934                   -66.5583  \n",
       "..                         ...                        ...  \n",
       "751                  -166.0632                  -212.9824  \n",
       "752                  -120.5312                  -121.5467  \n",
       "753                  -207.2320                  -229.7496  \n",
       "754                  -180.0185                  -221.9074  \n",
       "755                  -192.1787                  -211.4916  \n",
       "\n",
       "[756 rows x 270 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A_and_C = a_dataframe.iloc[:, [0,2]] get columns with index\n",
    "index_list,var_list= zip(*feature_tuple) #unzip the feature tuple\n",
    "index_list=list(index_list[:270])\n",
    "#print(index_list)\n",
    "t_df=file.iloc[:,index_list]\n",
    "t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aali7075/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_vals=t_df\n",
    "x, x_test, y, y_test = train_test_split(x_vals, y_vals, test_size = .25)\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(x, y)\n",
    "y_pred=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.8042328042328042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.65      0.62        46\n",
      "           1       0.88      0.85      0.87       143\n",
      "\n",
      "    accuracy                           0.80       189\n",
      "   macro avg       0.74      0.75      0.74       189\n",
      "weighted avg       0.81      0.80      0.81       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score: ',accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data, We can see that the model struggles with correctly classifying when a person does not have parkison. For the 0 class indenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107, 132, 17, 171, 181, 58, 24, 122, 22, 126]\n"
     ]
    }
   ],
   "source": [
    "x_feats=clf.feature_importances_\n",
    "#print(x)\n",
    "x_sorted=np.sort(x_feats)[::-1]\n",
    "x_sorted\n",
    "\n",
    "important_feats=[]\n",
    "\n",
    "for val in x_sorted:\n",
    "    for i in range(len(x_feats)):\n",
    "        if val==x_feats[i]:\n",
    "            important_feats.append(i)\n",
    "print(important_feats[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets find the optimal amount of estimators using a param grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=6,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "Best parameter is  {'min_samples_split': 6, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "param_grid={'n_estimators' : [100,150,200,250,300], 'min_samples_split': [2,4,6]}\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "check = GridSearchCV(clf, param_grid, cv=3);\n",
    "check.fit(x, y)\n",
    "\n",
    "\n",
    "print(check.best_estimator_)  #Gives parameters that minimize the lost function the best\n",
    "print(\"Best parameter is \", check.best_params_)\n",
    "#print(check.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters are min_samples_split=6 and n_estimators=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals=t_df\n",
    "x, x_test, y, y_test = train_test_split(x_vals, y_vals, test_size = .25)\n",
    "clf = RandomForestClassifier(random_state=42, min_samples_split=6, n_estimators=200)\n",
    "clf.fit(x, y)\n",
    "y_pred=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.8306878306878307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.84      0.63        32\n",
      "           1       0.96      0.83      0.89       157\n",
      "\n",
      "    accuracy                           0.83       189\n",
      "   macro avg       0.73      0.84      0.76       189\n",
      "weighted avg       0.88      0.83      0.85       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score: ',accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found the best parameters for a tree method let's create a new tree model (Adaboost!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
